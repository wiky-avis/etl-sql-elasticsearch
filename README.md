# etl-sql-elasticsearch
Python-скрипт, который перегружает данные из SQLite в индекс movies в Elasticsearch.

## Установка

Склонируйте репозиторий на локальную машину:

  `git clone https://github.com/wiky-avis/etl-sql-elasticsearch.git`
  
Создайте виртуальное окружение:

  `python -m venv venv`
  
  и активируйте его (команда зависит от ОС:

  `source venv/bin/activate`
  
Ус тановите необходимые зависимости:

  `pip install -r requirements.txt`

Запустите docker-compose:

  `docker-compose up -d`

## Запуск скрипта

  `python sqlite3_es_bulk.py`

После запуска скрипт автоматически создаст индекс movies в Elasticsearch и загрузит в него данные. База данных с фильмами и набор тестов для [Postman](https://www.postman.com/downloads/) в комплекте.


У решения есть два предположения:
• Данных не очень много, поэтому грузим всё, что есть.
• Можно загрузить всю таблицу сценаристов в память, потому что их не так много.

Из этих предположений вытекают недостатки решения:
• Если данных будет много, то запрос может «убить» SQLite, или придётся очень долго ждать загрузки данных.
• Elasticsearch плохо переваривает пачки данных большого размера за один запрос. Например, те, где больше 10 000 записей.
• Загрузка сценаристов в память может забить весь ОЗУ, если их список увеличится.
• Если такой процесс запустить в cron, то два запуска могут наложиться друг на друга и нагрузить систему ещё сильнее.
• Из-за увеличения количества записей выгрузка БД может обернуться большими затратами ресурсов на загрузку дублирующей информации.
